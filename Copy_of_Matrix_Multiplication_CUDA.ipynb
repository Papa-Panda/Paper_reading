{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Papa-Panda/Paper_reading/blob/main/Copy_of_Matrix_Multiplication_CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSzCDzbxeHgm",
        "outputId": "1518255f-ff23-44e5-d5ad-b297e335a46e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dev_array.h\n"
          ]
        }
      ],
      "source": [
        "%%writefile dev_array.h\n",
        "\n",
        "#ifndef _DEV_ARRAY_H_\n",
        "#define _DEV_ARRAY_H_\n",
        "\n",
        "#include <stdexcept>\n",
        "#include <algorithm>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "template <class T>\n",
        "class dev_array\n",
        "{\n",
        "    public:\n",
        "      explicit dev_array()\n",
        "        : start_(0),\n",
        "          end_(0)\n",
        "      {}\n",
        "\n",
        "      explicit dev_array(size_t size)\n",
        "      {\n",
        "          allocate(size);\n",
        "      }\n",
        "\n",
        "      ~dev_array(){\n",
        "          free();\n",
        "      }\n",
        "\n",
        "      void resize(size_t size){\n",
        "          free();\n",
        "          allocate(size);\n",
        "      }\n",
        "\n",
        "      size_t getSize() const {\n",
        "          return end_ - start_;\n",
        "      }\n",
        "\n",
        "      const T* getData() const {\n",
        "          return start_;\n",
        "      }\n",
        "\n",
        "      T* getData() {\n",
        "          return start_;\n",
        "      }\n",
        "\n",
        "      void set(const T* src, size_t size) {\n",
        "          size_t min = std::min(size, getSize());\n",
        "          cudaError_t result = cudaMemcpy(start_, src, min * sizeof(T), cudaMemcpyHostToDevice);\n",
        "          if (result != cudaSuccess)\n",
        "          {\n",
        "              throw std::runtime_error(\"Failed to copy to Device Memory\");\n",
        "          }\n",
        "      }\n",
        "\n",
        "      void get(T* dest, size_t size){\n",
        "          size_t min = std::min(size, getSize());\n",
        "          cudaError_t result = cudaMemcpy(dest, start_, min * sizeof(T), cudaMemcpyDeviceToHost);\n",
        "          if (result != cudaSuccess) {\n",
        "              throw std::runtime_error(\"Failed to copy to Host Memory\");\n",
        "          }\n",
        "      }\n",
        "\n",
        "    private:\n",
        "      void allocate(size_t size){\n",
        "          cudaError_t result = cudaMalloc((void**)&start_, size * sizeof(T));\n",
        "          if (result != cudaSuccess){\n",
        "              start_ = end_ = 0;\n",
        "              throw std::runtime_error(\"Failed to allocate Device Memory\");\n",
        "          }\n",
        "      }\n",
        "\n",
        "      void free(){\n",
        "          if (start_ != 0){\n",
        "              cudaFree(start_);\n",
        "              start_ = end_ = 0;\n",
        "          }\n",
        "      }\n",
        "\n",
        "      T* start_;\n",
        "      T* end_;\n",
        "};\n",
        "\n",
        "#endif\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kernel.h\n",
        "\n",
        "#ifndef KERNEL_CUH_\n",
        "#define KERNEL_CUH_\n",
        "\n",
        "void matrixMultiplication(float *A, float *B, float *C, int N);\n",
        "\n",
        "#endif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRewHTZmCIYM",
        "outputId": "f89798af-41d6-42c9-f349-a7e40f0228b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing kernel.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kernel.cu\n",
        "\n",
        "#include <math.h>\n",
        "#include <iostream>\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"kernel.h\"\n",
        "#include <stdlib.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__\n",
        "void matrixMultiplicationKernel(float *A, float *B, float *C, int N){\n",
        "    int ROW = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int COL = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    float tempSum = 0;\n",
        "\n",
        "    if (ROW < N && COL < N){\n",
        "        for(int i = 0; i < N; i++){\n",
        "            tempSum += A[ROW * N + i] * B[i * N + COL];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    C[ROW * N + COL] = tempSum;\n",
        "}\n",
        "\n",
        "void matrixMultiplication(float *A, float *B, float *C, int N){\n",
        "\n",
        "    dim3 threadsPerBlock(N, N);\n",
        "    dim3 blocksPerGrid(1, 1);\n",
        "\n",
        "      if (N*N > 512){\n",
        "          threadsPerBlock.x = 512;\n",
        "          threadsPerBlock.y = 512;\n",
        "          blocksPerGrid.x = ceil(double(N)/double(threadsPerBlock.x));\n",
        "          blocksPerGrid.y = ceil(double(N)/double(threadsPerBlock.y));\n",
        "      }\n",
        "\n",
        "      matrixMultiplicationKernel<<<blocksPerGrid, threadsPerBlock>>>(A, B, C, N);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJR-kyxvChUo",
        "outputId": "6af72bac-c38a-4f3a-981d-0ac70f525932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrixmul.cu\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include \"kernel.h\"\n",
        "#include \"kernel.cu\"\n",
        "#include \"dev_array.h\"\n",
        "#include <math.h>\n",
        "\n",
        "int main(){\n",
        "\n",
        "    int N = 3;\n",
        "    int SIZE = N*N;\n",
        "\n",
        "    vector<float> h_A(SIZE);\n",
        "    vector<float> h_B(SIZE);\n",
        "    vector<float> h_C(SIZE);\n",
        "\n",
        "    for (int i=0; i<N; i++){\n",
        "        for (int j=0; j<N; j++){\n",
        "            h_A[i*N+j] = sin(i);\n",
        "            h_B[i*N+j] = cos(j);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    dev_array<float> d_A(SIZE);\n",
        "    dev_array<float> d_B(SIZE);\n",
        "    dev_array<float> d_C(SIZE);\n",
        "\n",
        "    d_A.set(&h_A[0], SIZE);\n",
        "    d_B.set(&h_B[0], SIZE);\n",
        "\n",
        "    matrixMultiplication(d_A.getData(), d_B.getData(), d_C.getData(), N);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    d_C.get(&h_C[0], SIZE);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    //Testing purpose to compare with CPU Calculation\n",
        "    float *cpu_C;\n",
        "    cpu_C = new float[SIZE];\n",
        "\n",
        "    float sum;\n",
        "    for (int row = 0; row < N; row++){\n",
        "        for (int col = 0; col < N; col++){\n",
        "            sum = 0.0f;\n",
        "            for(int n = 0; n < N; n++){\n",
        "                sum += h_A[row * N + n] * h_B[N * n + col];\n",
        "            }\n",
        "\n",
        "            cpu_C[row * N + col] = sum;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    double err = 0;\n",
        "\n",
        "    for (int ROW = 0; ROW < N; ROW++){\n",
        "        for (int COL = 0; COL < N; COL++){\n",
        "            err += cpu_C[ROW * N + COL] - h_C[ROW * N + COL];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    std::cout << \"Error: \"<< err << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjYSpaRIzY0O",
        "outputId": "c4911f6c-e677-4aa7-91fb-433b2b300261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrixmul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvcc matrixmul.cu -o matrixmul\n",
        "./matrixmul\n",
        "\n",
        "nvprof ./matrixmul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP3D0sv3ew8W",
        "outputId": "0587007d-b41a-4d76-be42-16ad432827f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: -1.19209e-07\n",
            "==931== NVPROF is profiling process 931, command: ./matrixmul\n",
            "Error: -1.19209e-07\n",
            "==931== Profiling application: ./matrixmul\n",
            "==931== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   42.46%  3.8720us         1  3.8720us  3.8720us  3.8720us  matrixMultiplicationKernel(float*, float*, float*, int)\n",
            "                   35.09%  3.2000us         2  1.6000us  1.3440us  1.8560us  [CUDA memcpy HtoD]\n",
            "                   22.46%  2.0480us         1  2.0480us  2.0480us  2.0480us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.74%  289.25ms         3  96.417ms  3.2870us  289.24ms  cudaMalloc\n",
            "                    0.12%  340.67us         1  340.67us  340.67us  340.67us  cuDeviceTotalMem\n",
            "                    0.06%  165.02us       101  1.6330us     141ns  83.500us  cuDeviceGetAttribute\n",
            "                    0.05%  142.05us         3  47.349us  4.9200us  121.81us  cudaFree\n",
            "                    0.01%  40.979us         3  13.659us  8.2950us  17.555us  cudaMemcpy\n",
            "                    0.01%  28.634us         1  28.634us  28.634us  28.634us  cuDeviceGetName\n",
            "                    0.01%  23.214us         1  23.214us  23.214us  23.214us  cudaLaunchKernel\n",
            "                    0.00%  8.6870us         2  4.3430us  1.6420us  7.0450us  cudaDeviceSynchronize\n",
            "                    0.00%  6.6810us         1  6.6810us  6.6810us  6.6810us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.0970us         3     699ns     267ns  1.5320us  cuDeviceGetCount\n",
            "                    0.00%  1.3240us         2     662ns     181ns  1.1430us  cuDeviceGet\n",
            "                    0.00%     314ns         1     314ns     314ns     314ns  cuDeviceGetUuid\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}