{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOShl5AMOPHJ11NlmiAd1Yo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Papa-Panda/Paper_reading/blob/main/DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from https://chatgpt.com/c/67a6f8e8-31cc-800e-b227-052ea4820b5e"
      ],
      "metadata": {
        "id": "fiKWEcWrUhL2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[atari] ale-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDXNZMRWVcGY",
        "outputId": "1c939f3c-5949-4655-d342-a0fd11d3fd0c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.11/dist-packages (0.10.1)\n",
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env_specs = gym.registry.keys()\n",
        "print(list(env_specs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhxM-f0hV751",
        "outputId": "9bde1da4-b630-423a-e619-794dbe00939f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CartPole-v0', 'CartPole-v1', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Acrobot-v1', 'phys2d/CartPole-v0', 'phys2d/CartPole-v1', 'phys2d/Pendulum-v0', 'LunarLander-v3', 'LunarLanderContinuous-v3', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'CarRacing-v3', 'Blackjack-v1', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'CliffWalking-v0', 'Taxi-v3', 'tabular/Blackjack-v0', 'tabular/CliffWalking-v0', 'Reacher-v2', 'Reacher-v4', 'Reacher-v5', 'Pusher-v2', 'Pusher-v4', 'Pusher-v5', 'InvertedPendulum-v2', 'InvertedPendulum-v4', 'InvertedPendulum-v5', 'InvertedDoublePendulum-v2', 'InvertedDoublePendulum-v4', 'InvertedDoublePendulum-v5', 'HalfCheetah-v2', 'HalfCheetah-v3', 'HalfCheetah-v4', 'HalfCheetah-v5', 'Hopper-v2', 'Hopper-v3', 'Hopper-v4', 'Hopper-v5', 'Swimmer-v2', 'Swimmer-v3', 'Swimmer-v4', 'Swimmer-v5', 'Walker2d-v2', 'Walker2d-v3', 'Walker2d-v4', 'Walker2d-v5', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'Ant-v5', 'Humanoid-v2', 'Humanoid-v3', 'Humanoid-v4', 'Humanoid-v5', 'HumanoidStandup-v2', 'HumanoidStandup-v4', 'HumanoidStandup-v5', 'GymV21Environment-v0', 'GymV26Environment-v0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import gymnasium as gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import random\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# 创建 CartPole 环境\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "state_size = env.observation_space.shape[0]  # 状态维度\n",
        "action_size = env.action_space.n  # 动作数量\n",
        "\n",
        "# 超参数\n",
        "gamma = 0.99  # 折扣因子\n",
        "epsilon = 1.0  # 初始探索率\n",
        "epsilon_min = 0.1\n",
        "epsilon_decay = 0.995\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "memory_size = 10000\n",
        "target_update_freq = 10  # 目标网络更新频率\n",
        "episodes = 500  # 训练回合数\n",
        "\n",
        "# 经验回放缓冲区\n",
        "memory = deque(maxlen=memory_size)\n",
        "\n",
        "# 记录奖励\n",
        "reward_history = []\n",
        "\n",
        "# DQN 网络\n",
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(24, activation='relu', input_shape=(state_size,)),\n",
        "        keras.layers.Dense(24, activation='relu'),\n",
        "        keras.layers.Dense(action_size, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
        "    return model\n",
        "\n",
        "# 初始化网络\n",
        "model = build_model()\n",
        "target_model = build_model()\n",
        "target_model.set_weights(model.get_weights())  # 复制初始权重\n",
        "\n",
        "# 画图函数\n",
        "def plot_frame(frame):\n",
        "    plt.imshow(frame)\n",
        "    plt.axis(\"off\")\n",
        "    display(plt.gcf())\n",
        "    clear_output(wait=True)\n",
        "\n",
        "# 训练 DQN\n",
        "for episode in range(episodes):\n",
        "    state, _ = env.reset()\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "    total_reward = 0\n",
        "\n",
        "    for step in range(500):  # CartPole-v1 最多 500 步\n",
        "        # 选择动作（ε-贪心）\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            q_values = model.predict(state, verbose=0)\n",
        "            action = np.argmax(q_values[0])\n",
        "\n",
        "        # 采取动作\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "        next_state = np.reshape(next_state, [1, state_size])\n",
        "\n",
        "        # 存储经验\n",
        "        memory.append((state, action, reward, next_state, done))\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        # 渲染并可视化\n",
        "        frame = env.render()\n",
        "        plot_frame(frame)\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    reward_history.append(total_reward)  # 记录每轮奖励\n",
        "\n",
        "    print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
        "\n",
        "    # 经验回放训练\n",
        "    if len(memory) > batch_size:\n",
        "        minibatch = random.sample(memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target_q = model.predict(state, verbose=0)\n",
        "            if done:\n",
        "                target_q[0][action] = reward\n",
        "            else:\n",
        "                future_q = np.max(target_model.predict(next_state, verbose=0))\n",
        "                target_q[0][action] = reward + gamma * future_q\n",
        "            model.fit(state, target_q, epochs=1, verbose=0)\n",
        "\n",
        "    # 目标网络更新\n",
        "    if episode % target_update_freq == 0:\n",
        "        target_model.set_weights(model.get_weights())\n",
        "\n",
        "    # 探索率衰减\n",
        "    if epsilon > epsilon_min:\n",
        "        epsilon *= epsilon_decay\n",
        "\n",
        "env.close()  # 训练完成后关闭环境\n",
        "\n",
        "# 绘制奖励趋势图\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(reward_history, label=\"Total Reward per Episode\")\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Total Reward\")\n",
        "plt.title(\"CartPole DQN Learning Progress\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Q9C6bMiwVU6T",
        "outputId": "48aa3635-ffe1-4cba-cef5-b0f88306ed52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BY8lnLU-Y52x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}