{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEnS8ogHr92pqtogdm4/Nn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Papa-Panda/Paper_reading/blob/main/DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from https://chatgpt.com/c/67a6f8e8-31cc-800e-b227-052ea4820b5e"
      ],
      "metadata": {
        "id": "fiKWEcWrUhL2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[atari] ale-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDXNZMRWVcGY",
        "outputId": "1c939f3c-5949-4655-d342-a0fd11d3fd0c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.11/dist-packages (0.10.1)\n",
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env_specs = gym.registry.keys()\n",
        "print(list(env_specs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhxM-f0hV751",
        "outputId": "9bde1da4-b630-423a-e619-794dbe00939f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CartPole-v0', 'CartPole-v1', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Acrobot-v1', 'phys2d/CartPole-v0', 'phys2d/CartPole-v1', 'phys2d/Pendulum-v0', 'LunarLander-v3', 'LunarLanderContinuous-v3', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'CarRacing-v3', 'Blackjack-v1', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'CliffWalking-v0', 'Taxi-v3', 'tabular/Blackjack-v0', 'tabular/CliffWalking-v0', 'Reacher-v2', 'Reacher-v4', 'Reacher-v5', 'Pusher-v2', 'Pusher-v4', 'Pusher-v5', 'InvertedPendulum-v2', 'InvertedPendulum-v4', 'InvertedPendulum-v5', 'InvertedDoublePendulum-v2', 'InvertedDoublePendulum-v4', 'InvertedDoublePendulum-v5', 'HalfCheetah-v2', 'HalfCheetah-v3', 'HalfCheetah-v4', 'HalfCheetah-v5', 'Hopper-v2', 'Hopper-v3', 'Hopper-v4', 'Hopper-v5', 'Swimmer-v2', 'Swimmer-v3', 'Swimmer-v4', 'Swimmer-v5', 'Walker2d-v2', 'Walker2d-v3', 'Walker2d-v4', 'Walker2d-v5', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'Ant-v5', 'Humanoid-v2', 'Humanoid-v3', 'Humanoid-v4', 'Humanoid-v5', 'HumanoidStandup-v2', 'HumanoidStandup-v4', 'HumanoidStandup-v5', 'GymV21Environment-v0', 'GymV26Environment-v0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import random\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# 创建 CartPole 环境，指定渲染模式\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "state_size = env.observation_space.shape[0]  # 状态维度\n",
        "action_size = env.action_space.n  # 动作数量\n",
        "\n",
        "# 超参数\n",
        "gamma = 0.99  # 折扣因子\n",
        "epsilon = 1.0  # 初始探索率\n",
        "epsilon_min = 0.1\n",
        "epsilon_decay = 0.995\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "memory_size = 10000\n",
        "target_update_freq = 10  # 目标网络更新频率\n",
        "episodes = 500  # 训练回合数\n",
        "\n",
        "# 经验回放缓冲区\n",
        "memory = deque(maxlen=memory_size)\n",
        "\n",
        "# DQN 网络\n",
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(24, activation='relu', input_shape=(state_size,)),\n",
        "        keras.layers.Dense(24, activation='relu'),\n",
        "        keras.layers.Dense(action_size, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
        "    return model\n",
        "\n",
        "# 初始化网络\n",
        "model = build_model()\n",
        "target_model = build_model()\n",
        "target_model.set_weights(model.get_weights())  # 复制初始权重\n",
        "\n",
        "# 画图函数\n",
        "def plot_frame(frame):\n",
        "    plt.imshow(frame)\n",
        "    plt.axis(\"off\")\n",
        "    display(plt.gcf())  # 在 Jupyter Notebook 显示\n",
        "    clear_output(wait=True)  # 清除上一帧，防止重叠\n",
        "\n",
        "# 训练 DQN\n",
        "for episode in range(episodes):\n",
        "    state, _ = env.reset()\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "    total_reward = 0\n",
        "\n",
        "    for step in range(200):  # CartPole 最多 200 步\n",
        "        # 选择动作（ε-贪心）\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            q_values = model.predict(state, verbose=0)\n",
        "            action = np.argmax(q_values[0])\n",
        "\n",
        "        # 采取动作\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "        next_state = np.reshape(next_state, [1, state_size])\n",
        "\n",
        "        # 存储经验\n",
        "        memory.append((state, action, reward, next_state, done))\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        # 渲染并可视化\n",
        "        frame = env.render()\n",
        "        plot_frame(frame)\n",
        "\n",
        "        if done:\n",
        "            print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
        "            break\n",
        "\n",
        "    # 经验回放训练\n",
        "    if len(memory) > batch_size:\n",
        "        minibatch = random.sample(memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target_q = model.predict(state, verbose=0)\n",
        "            if done:\n",
        "                target_q[0][action] = reward\n",
        "            else:\n",
        "                future_q = np.max(target_model.predict(next_state, verbose=0))\n",
        "                target_q[0][action] = reward + gamma * future_q\n",
        "            model.fit(state, target_q, epochs=1, verbose=0)\n",
        "\n",
        "    # 目标网络更新\n",
        "    if episode % target_update_freq == 0:\n",
        "        target_model.set_weights(model.get_weights())\n",
        "\n",
        "    # 探索率衰减\n",
        "    if epsilon > epsilon_min:\n",
        "        epsilon *= epsilon_decay\n",
        "\n",
        "env.close()  # 训练完成后关闭环境"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Q9C6bMiwVU6T",
        "outputId": "6c8fe8d0-95a9-4860-eab3-8d475dde478b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFeCAYAAAAYIxzjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAADeBJREFUeJzt3c2PXfV5wPHnnDuvnrFnbNkDOHXjAgGRiAapKYIEhSqRKjbddUHXVGJTiX+iS1SpS3aV2lUVdUWlSpEqpKoVbUXThiYpgQRsjDHM2DPjeblz387pApqQ4nBuMHPvnfN8Putnxs/GM9+553fOKeq6rgMASKuc9gIAwHSJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJDc37QWAu1fXdUTUEXUddV3H4GAnDjavxMHm27H/4Ttx5uJDcfH3/iiKopj2qsAMEgNwwg26e3G4dfXjX/7vxMHmlRgc7ERE/YuZhZX1GPUOY25pZWp7ArNLDMAJd+M//yFu/PD7nznT3X4/erc3xQBwR84MQALdm+9Gd+fGtNcAZpQYgBNuZeN3Yv7U2rTXAE4wMQAn3NL6vTG32Pzxf12NPj5oCPCrxACccAur56JcWGqc6+/djGo4mMBGwEkjBuCEm1s8FWVnvnHu9vs/jVH/YAIbASeNGIAk9t//aQx7h9NeA5hBYgBaYP3yY1GM8ekAwJ2IAWiB1Y37o+w0PzakGvQcIgQ+RQxACyyubURRNP937m5fj08+mRAgQgxAK8wvrUSMEQPbb/8g6qqawEbASSIGIJHdq69HuEwA/D9iAFpi46vfnvYKwAklBqAlVu97aKy5YW//mDcBThoxAC2xfPa+sea6t9475k2Ak0YMQEt0FpbHmrv51r8f8ybASSMGIJnb13487RWAGSMGoCWKshMXHhnvEKEHDwGfJAagJYqyjNV77m+cq+sqhkcOEQK/JAagNYpYXNtonKqrURztfjCBfYCTQgxASxRFEeXcQuNcNeh/9PAhgI+JAUimroZxsHll2msAM0QMQIssnFqPs/d/Y6xZhwiB/yMGoEXKhaVYXr+3ca4a9mN4dDCBjYCTQAxAi5Sd+ZhfWW+cG/W7MTjcOfZ9gJNBDECLFEURRdn837q/vx0HH749gY2Ak0AMQEKj/mH09m5Oew1gRogBaJnVex6I1Xu/MsZk7RAhEBFiAFpn/tRaLKysNc4NuvsxGhxNYCNg1okBaJnOwvJYbzAcHO7EqHc4gY2AWScGoGWKooiIonHucOtq9Pa2jn8hYOaJAUhqcLjrkwEgIsQAtNL5h78Zi6fPN87VtUOEgBiAVlpc24hyYalxrnd7M+pqOIGNgFkmBqCF5pdWoyznGud23/1RjPruKIDsxAAktnf9f9xeCIgBaKuzD3wjirIz1qxzA5CbGICWWr1weawYqIb9CWwDzDIxAC21dPa+iKL5eQNH2+9PYBtglokBaKm5pdUoxnj40Nabr0aEywSQmRiA5Hav/neEMwOQmhiAFrvw1aenvQJwAogBaLHVex8ca27oWQOQmhiAFls+e98YU3V0b7137LsAs0sMQEsVRRFzSyvNg3UdN9989fgXAmaWGABi7/ob014BmCIxAC1Wdubj/MPfGmvWUwghLzEALVaUnTh14bcb5+qqilH/cAIbAbNIDECbFWUsnb7QOFaPBtHb3ZzAQsAsEgPQYkVRRDm/2Dg37Hdj5+rrE9gImEViAIh6NHB7ISQmBqDlFk+fj/Uvf32MydohQkhKDEDLdRaWY3Fto3GuGvZj1O9OYCNg1ogBaLlybiHml880zg17hzE43J3ARsCsEQPQckVZRtGZa5w72v0wDjavTGAjYNaIASAiIka9g+gfbE97DWAKxAAkcObiw7Fy4XLzYO0QIWQkBiCB+VNrMbd8unFueLQf1bA/gY2AWSIGIIG5xZXoLCw3zvUPtt1RAAmJAUigKMsoiqJxbv/Gz6K/f2sCGwGzRAwAvzA43IlR/2jaawATJgYgiQuPfDvmV9abB+vKIUJIRgxAEotrG1HOLTTOHe1tRdTVBDYCZoUYgCTml05HUTY/fKi3+0FU1WgCGwGzQgxAEkVZRvMRwojtt38Q1aB37PsAs0MMQCZj3FHQ378VtcsEkIoYgEQuPfHHUZSdxrm6GjlECImIAUhk+dyXIsa4WNC99d7xLwPMDDEAicyfWhunBWLzJ/90/MsAM0MMAJ+y++6Ppr0CMEFiAJK58MjT014BmDFiAJJZ3bg81pzbCyEPMQDJLJ+92DxU19HduXH8ywAzQQxAIkVRxNzy6ca5uh7F1hv/PIGNgFkgBoBPq+vYv/HWtLcAJkQMQDKd+aU495Unxpr14CHIQQxAMkWnE6fOfalxrq6rGDlECCmIAUimKDuxePp841w17Ed/b2sCGwHTJgYgmaIoo7Ow1Dg37O7FztXXJ7ARMG1iALijatiPI7cXQgpiABJaWr8n1i59rXmwrh0ihATEACTUWTgVC6vnGueqYT+qoUOE0HZiABLqzC/G/PKZxrnh0X4MunsT2AiYJjEACRVlJ4rOXONcd/t6HG5emcBGwDSJAUiraJz46JOB2xPYBZgmMQBJrV36Wiyf+63mQYcIofXEACQ1v7Iec0srjXPDo4OoR8MJbARMixiApOaWVqMzv9g419u/GaPB0QQ2AqZFDEBSZdmJKJp/BNy+9pMYHOwc/0LA1DQfJwZm3mg0+lzX9auqirquoyh+/WHCweFODHrdGA7v/lJBWZZRlv4GgVkjBqAFnnnmmXjllVd+46977IGN+PM//U6cO738mXPf/e534r9+9sHn3O6XXnzxxXjhhRfu+vsAXywxAC0wGo0+11/uVz7YicFg1Dh3/sxSVKNRVHd5V0FVVXf19cDxEAOQ2M3dbgxHv/oLenuwETvDe2JYLcRieRDnF96Ly/euR1kWUY3cYghtJAYgsaqu45O/3q8dPRQ/7349uqPTUUUn5op+XOvtxtO/342/+f4PPxUOQDs4yQPJjaoq6jrig96X48f734yD0dmoYi4iihjWi7E73Ih3On8SxdzqtFcFjokYgOT+8nv/GgfD0/Efe38Yo1i448ygXo4/e+F7E94MmBQxAMm99d7N+OhiwWe/q+Czbj8ETjYxAMlt7R5OewVgysQAJOcdRIAYAKJT7cTvrv5jFHHnZw6UMYxvrf/dhLcCJkUMQHKjqo6/+Nt/iYuLb8UjK6/GUrn/URTUdUTVi97hjbjY+6u4dv2daa8KHBPPGQDi59e3YzAcxfzhq1FsvRFXts7G5u06YrgdN9//t/jrd9+Ka1u3p70mcEyKesy3mzz//PPHvQvwOb388stx/fr1z/31K0vz8QePXY6t3cO4efswtna7sbP/xb+2+Mknn4xHH330C/++wK/30ksvNc6M/cnAc889d1fLAMfntddeu6sYODgaxN+/+uYXuNGdPfHEE/Hss88e+78D/GbGjoHHH3/8OPcA7sKZM2emvcJYLl265GcJzCAHCAEgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyXlrIbTAU089FWtra9Neo9GDDz447RWAOxj7rYUAQDu5TAAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAk979vu8VxEK4AVwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}