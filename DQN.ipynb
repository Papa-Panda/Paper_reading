{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOShl5AMOPHJ11NlmiAd1Yo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Papa-Panda/Paper_reading/blob/main/DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from https://chatgpt.com/c/67a6f8e8-31cc-800e-b227-052ea4820b5e"
      ],
      "metadata": {
        "id": "fiKWEcWrUhL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[atari] ale-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDXNZMRWVcGY",
        "outputId": "1c939f3c-5949-4655-d342-a0fd11d3fd0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.11/dist-packages (0.10.1)\n",
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env_specs = gym.registry.keys()\n",
        "print(list(env_specs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhxM-f0hV751",
        "outputId": "9bde1da4-b630-423a-e619-794dbe00939f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CartPole-v0', 'CartPole-v1', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Acrobot-v1', 'phys2d/CartPole-v0', 'phys2d/CartPole-v1', 'phys2d/Pendulum-v0', 'LunarLander-v3', 'LunarLanderContinuous-v3', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'CarRacing-v3', 'Blackjack-v1', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'CliffWalking-v0', 'Taxi-v3', 'tabular/Blackjack-v0', 'tabular/CliffWalking-v0', 'Reacher-v2', 'Reacher-v4', 'Reacher-v5', 'Pusher-v2', 'Pusher-v4', 'Pusher-v5', 'InvertedPendulum-v2', 'InvertedPendulum-v4', 'InvertedPendulum-v5', 'InvertedDoublePendulum-v2', 'InvertedDoublePendulum-v4', 'InvertedDoublePendulum-v5', 'HalfCheetah-v2', 'HalfCheetah-v3', 'HalfCheetah-v4', 'HalfCheetah-v5', 'Hopper-v2', 'Hopper-v3', 'Hopper-v4', 'Hopper-v5', 'Swimmer-v2', 'Swimmer-v3', 'Swimmer-v4', 'Swimmer-v5', 'Walker2d-v2', 'Walker2d-v3', 'Walker2d-v4', 'Walker2d-v5', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'Ant-v5', 'Humanoid-v2', 'Humanoid-v3', 'Humanoid-v4', 'Humanoid-v5', 'HumanoidStandup-v2', 'HumanoidStandup-v4', 'HumanoidStandup-v5', 'GymV21Environment-v0', 'GymV26Environment-v0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import gymnasium as gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import random\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# 创建 CartPole 环境\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "state_size = env.observation_space.shape[0]  # 状态维度\n",
        "action_size = env.action_space.n  # 动作数量\n",
        "\n",
        "# 超参数\n",
        "gamma = 0.99  # 折扣因子\n",
        "epsilon = 1.0  # 初始探索率\n",
        "epsilon_min = 0.1\n",
        "epsilon_decay = 0.995\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "memory_size = 10000\n",
        "target_update_freq = 10  # 目标网络更新频率\n",
        "episodes = 500  # 训练回合数\n",
        "\n",
        "# 经验回放缓冲区\n",
        "memory = deque(maxlen=memory_size)\n",
        "\n",
        "# 记录奖励\n",
        "reward_history = []\n",
        "\n",
        "# DQN 网络\n",
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(24, activation='relu', input_shape=(state_size,)),\n",
        "        keras.layers.Dense(24, activation='relu'),\n",
        "        keras.layers.Dense(action_size, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
        "    return model\n",
        "\n",
        "# 初始化网络\n",
        "model = build_model()\n",
        "target_model = build_model()\n",
        "target_model.set_weights(model.get_weights())  # 复制初始权重\n",
        "\n",
        "# 画图函数\n",
        "def plot_frame(frame):\n",
        "    plt.imshow(frame)\n",
        "    plt.axis(\"off\")\n",
        "    display(plt.gcf())\n",
        "    clear_output(wait=True)\n",
        "\n",
        "# 训练 DQN\n",
        "for episode in range(episodes):\n",
        "    state, _ = env.reset()\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "    total_reward = 0\n",
        "\n",
        "    for step in range(500):  # CartPole-v1 最多 500 步\n",
        "        # 选择动作（ε-贪心）\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            q_values = model.predict(state, verbose=0)\n",
        "            action = np.argmax(q_values[0])\n",
        "\n",
        "        # 采取动作\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "        next_state = np.reshape(next_state, [1, state_size])\n",
        "\n",
        "        # 存储经验\n",
        "        memory.append((state, action, reward, next_state, done))\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        # 渲染并可视化\n",
        "        frame = env.render()\n",
        "        plot_frame(frame)\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    reward_history.append(total_reward)  # 记录每轮奖励\n",
        "\n",
        "    print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
        "\n",
        "    # 经验回放训练\n",
        "    if len(memory) > batch_size:\n",
        "        minibatch = random.sample(memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target_q = model.predict(state, verbose=0)\n",
        "            if done:\n",
        "                target_q[0][action] = reward\n",
        "            else:\n",
        "                future_q = np.max(target_model.predict(next_state, verbose=0))\n",
        "                target_q[0][action] = reward + gamma * future_q\n",
        "            model.fit(state, target_q, epochs=1, verbose=0)\n",
        "\n",
        "    # 目标网络更新\n",
        "    if episode % target_update_freq == 0:\n",
        "        target_model.set_weights(model.get_weights())\n",
        "\n",
        "    # 探索率衰减\n",
        "    if epsilon > epsilon_min:\n",
        "        epsilon *= epsilon_decay\n",
        "\n",
        "env.close()  # 训练完成后关闭环境\n",
        "\n",
        "# 绘制奖励趋势图\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(reward_history, label=\"Total Reward per Episode\")\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Total Reward\")\n",
        "plt.title(\"CartPole DQN Learning Progress\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Q9C6bMiwVU6T",
        "outputId": "ab9a27b8-b390-424b-b0c9-f6db0fe53b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BY8lnLU-Y52x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}