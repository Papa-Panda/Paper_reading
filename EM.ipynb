{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Papa-Panda/Paper_reading/blob/main/EM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# --- 1. Generate Synthetic Data ---\n",
        "# We create a dataset with 4 distinct clusters to simulate real-world data\n",
        "# where groupings are present but not labeled.\n",
        "print(\"Generating synthetic data with 4 clusters...\")\n",
        "X, y_true = make_blobs(n_samples=600, centers=4,\n",
        "                       cluster_std=0.8, random_state=42)\n",
        "\n",
        "# Plot the raw, unlabeled data to see what we're starting with\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(X[:, 0], X[:, 1], s=20, color='gray')\n",
        "plt.title('Unlabeled Synthetic Data')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- 2. Apply the EM Algorithm using GaussianMixture ---\n",
        "# We instantiate the GaussianMixture model. The key parameter is `n_components`,\n",
        "# which is the number of clusters we are looking for.\n",
        "# The .fit() method runs the Expectation-Maximization algorithm to find the\n",
        "# parameters of the Gaussian distributions that best fit the data.\n",
        "print(\"Applying the EM algorithm via GaussianMixture...\")\n",
        "gmm = GaussianMixture(n_components=4, random_state=42, covariance_type='full')\n",
        "gmm.fit(X)\n",
        "\n",
        "# Predict the cluster for each data point using the trained model\n",
        "labels = gmm.predict(X)\n",
        "\n",
        "\n",
        "# --- 3. Visualize the Results ---\n",
        "# Now we plot the data again, but this time we color the points according to\n",
        "# the cluster labels found by the EM algorithm.\n",
        "print(\"Visualizing the clustering results...\")\n",
        "plt.figure(figsize=(12, 9))\n",
        "scatter = plt.scatter(X[:, 0], X[:, 1], c=labels, s=20, cmap='viridis', zorder=2)\n",
        "\n",
        "# We can also get the cluster centers learned by the algorithm\n",
        "centers = gmm.means_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=250, marker='X', zorder=3, label='Learned Centers')\n",
        "\n",
        "# To better visualize the \"shape\" of each cluster, we can draw ellipses\n",
        "# representing the covariance of each Gaussian component.\n",
        "for i in range(gmm.n_components):\n",
        "    # Get the covariance matrix for the i-th component\n",
        "    covariance = gmm.covariances_[i]\n",
        "\n",
        "    # Calculate eigenvalues and eigenvectors to determine the ellipse's orientation and size\n",
        "    v, w = np.linalg.eigh(covariance)\n",
        "    v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
        "    u = w[0] / np.linalg.norm(w[0])\n",
        "    angle = np.arctan2(u[1], u[0])\n",
        "    angle = 180. * angle / np.pi  # Convert to degrees\n",
        "\n",
        "    # Create and add the ellipse patch to the plot\n",
        "    ellipse = plt.matplotlib.patches.Ellipse(gmm.means_[i], v[0], v[1], 180. + angle,\n",
        "                                              color='red', alpha=0.2, zorder=1)\n",
        "    ax = plt.gca()\n",
        "    ax.add_artist(ellipse)\n",
        "\n",
        "plt.title('Data Clustered by EM Algorithm (GMM)')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "# You can also inspect the probabilities of each point belonging to each cluster\n",
        "# This is the \"soft\" assignment from the E-step of the final iteration.\n",
        "probabilities = gmm.predict_proba(X)\n",
        "print(\"\\nSample of soft cluster assignments (probabilities):\")\n",
        "print(probabilities[:5].round(3))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating synthetic data with 4 clusters...\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "-bHOrRkxZJ24",
        "outputId": "d9d28b7f-fda8-41f5-cb27-8aaa78bd5b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}