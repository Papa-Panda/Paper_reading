{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Papa-Panda/Paper_reading/blob/main/flow_realnvp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rw1SUItXllAj"
      },
      "outputs": [],
      "source": [
        "# original paper\n",
        "# https://arxiv.org/abs/1605.08803\n",
        "\n",
        "# discussion\n",
        "# https://spaces.ac.cn/archives/5807\n",
        "\n",
        "# implementation from\n",
        "# https://gemini.google.com/app/64f9247342835580\n",
        "\n",
        "# my experiments\n",
        "# https://colab.research.google.com/drive/1zHZgSFbQ4driCZkEUv5kt1Q-sogo1OCs#scrollTo=r1wTrQH64SfM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80e3zuTfllkN",
        "outputId": "e92bffd5-030c-4880-e0a8-7b74a00bedcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Created data directory: ./data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.08MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 135kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.84MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch 1/20, Loss: -106.9629\n",
            "Epoch 2/20, Loss: -675.5767\n",
            "Epoch 3/20, Loss: -953.2217\n",
            "Epoch 4/20, Loss: -1092.2629\n",
            "Epoch 5/20, Loss: -1209.1622\n",
            "Epoch 6/20, Loss: -1323.4944\n",
            "Epoch 7/20, Loss: -1428.7873\n",
            "Epoch 8/20, Loss: -1533.7726\n",
            "Epoch 9/20, Loss: -1633.5576\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os # For checking if data directory exists\n",
        "\n",
        "# --- 1. Data Loading and Preprocessing ---\n",
        "def load_mnist_data(batch_size=128):\n",
        "    \"\"\"\n",
        "    Loads and preprocesses the MNIST dataset.\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): The batch size for the DataLoader.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing (train_loader, test_loader).\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(), # Converts PIL Image to PyTorch Tensor and scales to [0, 1]\n",
        "        # Flatten the 28x28 image to a 784-dimensional vector\n",
        "        transforms.Lambda(lambda x: x.view(-1)),\n",
        "        # Add a small amount of uniform noise for dequantization.\n",
        "        # This is crucial for discrete data (like pixel values) when using\n",
        "        # continuous normalizing flows. It effectively spreads the discrete\n",
        "        # pixel values over a continuous interval [0, 1/256) for each pixel.\n",
        "        transforms.Lambda(lambda x: x + torch.rand_like(x) / 256.0),\n",
        "    ])\n",
        "\n",
        "    # Ensure the data directory exists to store the downloaded MNIST dataset\n",
        "    data_dir = './data'\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.makedirs(data_dir)\n",
        "        print(f\"Created data directory: {data_dir}\")\n",
        "\n",
        "    # Load MNIST training and testing datasets\n",
        "    train_dataset = datasets.MNIST(data_dir, train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.MNIST(data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    # Create DataLoaders for efficient batching and shuffling\n",
        "    # num_workers > 0 can speed up data loading, especially on GPU\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2 if torch.cuda.is_available() else 0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2 if torch.cuda.is_available() else 0)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# --- 2. Define the Neural Network for the 's' (scale) and 't' (translation) functions ---\n",
        "class ScaleAndTranslateNet(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple multi-layer perceptron (MLP) used within the Affine Coupling Layer.\n",
        "    This network now outputs both scaling (s) and translation (t) factors.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        \"\"\"\n",
        "        Initializes the ScaleAndTranslateNet.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Dimension of the input to this network (size of x1).\n",
        "            hidden_dim (int): Number of units in the hidden layers.\n",
        "            output_dim (int): Dimension of the output from this network (2 * size of x2, for s and t).\n",
        "        \"\"\"\n",
        "        super(ScaleAndTranslateNet, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(), # Activation function\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(), # Activation function\n",
        "            nn.Linear(hidden_dim, output_dim) # Output dimension is 2 * (size of x2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass for the ScaleAndTranslateNet.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor (corresponding to x1 in the coupling layer).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor (concatenated s and t values).\n",
        "        \"\"\"\n",
        "        return self.net(x)\n",
        "\n",
        "# --- 3. Define the Affine Coupling Layer (RealNVP's core) ---\n",
        "class AffineCouplingLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    An affine coupling layer, a core component of the RealNVP model.\n",
        "    It splits the input into two parts, transforms one part affinely based on the other,\n",
        "    and leaves the other part unchanged. This ensures invertibility and a tractable\n",
        "    Jacobian determinant.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, mask_config):\n",
        "        \"\"\"\n",
        "        Initializes an Affine Coupling Layer.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): The total dimension of the input data.\n",
        "            hidden_dim (int): Hidden dimension for the internal ScaleAndTranslateNet.\n",
        "            mask_config (int): Determines how the input is split (0 for even indices as x1, 1 for odd).\n",
        "        \"\"\"\n",
        "        super(AffineCouplingLayer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.mask_config = mask_config\n",
        "\n",
        "        # Create a boolean mask to split the input for the current layer.\n",
        "        # If mask_config is 0, even-indexed dimensions are x1 (unmodified part),\n",
        "        # and odd-indexed dimensions are x2 (modified part).\n",
        "        # If mask_config is 1, odd-indexed dimensions are x1, and even-indexed are x2.\n",
        "        indices = torch.arange(input_dim)\n",
        "        if mask_config == 0:\n",
        "            self.mask = (indices % 2 == 0).float() # 1s for x1, 0s for x2\n",
        "        else:\n",
        "            self.mask = (indices % 2 != 0).float() # 1s for x1, 0s for x2\n",
        "\n",
        "        # Determine the dimensions for x1 (input to ScaleAndTranslateNet) and x2 (output from ScaleAndTranslateNet).\n",
        "        x1_dim = int(self.mask.sum().item())\n",
        "        x2_dim = int((1 - self.mask).sum().item())\n",
        "\n",
        "        # Initialize the internal neural network (s and t functions)\n",
        "        # It needs to output 2 * x2_dim (one for scale, one for translate)\n",
        "        self.scale_translate_net = ScaleAndTranslateNet(x1_dim, hidden_dim, 2 * x2_dim)\n",
        "\n",
        "    def forward(self, x, log_det_jacobian):\n",
        "        \"\"\"\n",
        "        Forward pass of the affine coupling layer: y = f(x).\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor.\n",
        "            log_det_jacobian (torch.Tensor): Accumulated log-determinant of the Jacobian from previous layers.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (output_tensor_y, updated_log_det_jacobian).\n",
        "        \"\"\"\n",
        "        mask = self.mask.to(x.device)\n",
        "        # Split x into x1 (unmodified part) and x2 (part to be transformed)\n",
        "        x1_unmasked = x * mask # Contains x1 values and zeros for x2 positions\n",
        "        x2_unmasked = x * (1 - mask) # Contains x2 values and zeros for x1 positions\n",
        "\n",
        "        # Extract the active values for x1 to feed into the scale_translate_net.\n",
        "        x1_active = x1_unmasked[:, mask.bool()]\n",
        "\n",
        "        # Compute the output of the scale_translate_net, which contains both s and t\n",
        "        st_output = self.scale_translate_net(x1_active)\n",
        "\n",
        "        # Split the output into scale (s) and translation (t) components\n",
        "        s, t = st_output.chunk(2, dim=1) # Splits along dimension 1 into two equal chunks\n",
        "\n",
        "        # Clamp s to prevent numerical instability with exp(s) (too large/small values)\n",
        "        s = torch.clamp(s, -5., 5.) # Common practice to stabilize training\n",
        "\n",
        "        # Apply the affine transformation: y2 = x2 * exp(s) + t\n",
        "        # We create a zero tensor with the same shape as x2_unmasked and fill\n",
        "        # the active (non-masked) positions with the transformed values.\n",
        "        y2_unmasked = torch.zeros_like(x2_unmasked)\n",
        "        y2_unmasked[:, (1 - mask).bool()] = x2_unmasked[:, (1 - mask).bool()] * torch.exp(s) + t\n",
        "        # following works well, too; even without changing the inverse function LOL\n",
        "        # y2_unmasked[:, (1 - mask).bool()] = x2_unmasked[:, (1 - mask).bool()] * s + t\n",
        "\n",
        "        # Combine y1 (which is just x1) and y2 to form the output y\n",
        "        y = x1_unmasked + y2_unmasked\n",
        "\n",
        "        # Add the log-determinant contribution from this affine coupling layer.\n",
        "        # For an affine transformation y_i = x_i * exp(s_i) + t_i, the Jacobian determinant\n",
        "        # is the product of exp(s_i) for the transformed dimensions.\n",
        "        # The log-determinant is therefore sum(s_i) over the transformed dimensions.\n",
        "        log_det_jacobian += s.sum(dim=1)\n",
        "\n",
        "        return y, log_det_jacobian\n",
        "\n",
        "    def inverse(self, y, log_det_jacobian):\n",
        "        \"\"\"\n",
        "        Inverse pass of the affine coupling layer: x = f_inverse(y).\n",
        "\n",
        "        Args:\n",
        "            y (torch.Tensor): Input tensor (output from forward pass).\n",
        "            log_det_jacobian (torch.Tensor): Accumulated log-determinant (not updated here).\n",
        "\n",
        "        Returns:\n",
        "            tuple: (output_tensor_x, unchanged_log_det_jacobian).\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure the mask is on the same device as the input tensor y\n",
        "        mask = self.mask.to(y.device)\n",
        "\n",
        "        # Split y into y1 (corresponding to x1) and y2 (corresponding to x2 * exp(s) + t)\n",
        "        y1_unmasked = y * mask\n",
        "        y2_unmasked = y * (1 - mask)\n",
        "\n",
        "        # Extract active values for y1 to feed into the scale_translate_net for inverse calculation\n",
        "        y1_active = y1_unmasked[:, mask.bool()]\n",
        "\n",
        "        # Compute s and t using y1_active\n",
        "        st_output = self.scale_translate_net(y1_active)\n",
        "        s, t = st_output.chunk(2, dim=1)\n",
        "        s = torch.clamp(s, -5., 5.) # Apply same clamping as in forward pass\n",
        "\n",
        "        # Apply the inverse transformation: x2 = (y2 - t) / exp(s)\n",
        "        x2_unmasked = torch.zeros_like(y2_unmasked)\n",
        "        x2_unmasked[:, (1 - mask).bool()] = (y2_unmasked[:, (1 - mask).bool()] - t) / torch.exp(s)\n",
        "\n",
        "        # Combine y1 (which is x1) and x2 to form the original input x\n",
        "        x = y1_unmasked + x2_unmasked\n",
        "        return x, log_det_jacobian # log_det_jacobian is not updated during inverse for coupling layer\n",
        "\n",
        "# --- 4. Define the RealNVP Model (Flow) ---\n",
        "class RealNVP(nn.Module):\n",
        "    \"\"\"\n",
        "    The RealNVP (Real Non-Volume Preserving) model.\n",
        "    It comprises a stack of affine coupling layers.\n",
        "    Unlike NICE, RealNVP typically does not have a separate global scaling layer\n",
        "    at the end, as scaling is handled within each affine coupling layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, num_coupling_layers, hidden_dim):\n",
        "        \"\"\"\n",
        "        Initializes the RealNVP model.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): The dimension of the input data (e.g., 784 for MNIST).\n",
        "            num_coupling_layers (int): The number of affine coupling layers to stack.\n",
        "            hidden_dim (int): The hidden dimension for the ScaleAndTranslateNet within each layer.\n",
        "        \"\"\"\n",
        "        super(RealNVP, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.num_coupling_layers = num_coupling_layers\n",
        "\n",
        "        # Create a list of affine coupling layers\n",
        "        self.coupling_layers = nn.ModuleList()\n",
        "        for i in range(num_coupling_layers):\n",
        "            # Alternate the mask configuration (0 or 1) for each coupling layer.\n",
        "            # This ensures that all dimensions of the input data are eventually\n",
        "            # transformed across the entire flow.\n",
        "            self.coupling_layers.append(AffineCouplingLayer(input_dim, hidden_dim, i % 2))\n",
        "\n",
        "        # RealNVP does not have a separate global scaling layer like NICE.\n",
        "        # The scaling is implicitly handled by the 's' component in each affine coupling layer.\n",
        "        # So, we remove self.log_s from here.\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the RealNVP model: transforms data x to latent variable z.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input data tensor.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (latent_variable_z, total_log_det_jacobian).\n",
        "        \"\"\"\n",
        "        # Initialize log_det_jacobian for the batch.\n",
        "        # It accumulates the log-determinant of the Jacobian for the entire transformation.\n",
        "        log_det_jacobian = torch.zeros(x.size(0)).to(x.device)\n",
        "\n",
        "        # Pass through all affine coupling layers\n",
        "        for layer in self.coupling_layers:\n",
        "            x, log_det_jacobian = layer(x, log_det_jacobian)\n",
        "\n",
        "        # The final output 'x' is now the latent variable 'z'\n",
        "        z = x\n",
        "\n",
        "        return z, log_det_jacobian\n",
        "\n",
        "    def inverse(self, z):\n",
        "        \"\"\"\n",
        "        Inverse pass of the RealNVP model: transforms latent variable z back to data x.\n",
        "\n",
        "        Args:\n",
        "            z (torch.Tensor): Latent variable tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Reconstructed data tensor x.\n",
        "        \"\"\"\n",
        "        # The latent variable z is directly the input to the inverse of the last coupling layer\n",
        "        x = z\n",
        "\n",
        "        # Inverse through coupling layers in reverse order.\n",
        "        # For sampling, we typically don't need to compute the log-determinant\n",
        "        # during the inverse pass, so we pass `None`.\n",
        "        for layer in reversed(self.coupling_layers):\n",
        "            x, _ = layer.inverse(x, None) # log_det_jacobian is not needed for inverse here\n",
        "\n",
        "        return x\n",
        "\n",
        "    def log_prob(self, x):\n",
        "        \"\"\"\n",
        "        Calculates the log-likelihood of the input data x under the RealNVP model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input data tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Log-likelihood for each data point in the batch.\n",
        "        \"\"\"\n",
        "        # Transform data x to latent variable z and get the total log-determinant of Jacobian\n",
        "        z, log_det_jacobian = self.forward(x)\n",
        "\n",
        "        # Calculate log-probability of z under the prior distribution (standard Gaussian).\n",
        "        # The prior is assumed to be a standard multivariate Gaussian: N(0, I).\n",
        "        # log p(z) = -0.5 * (z^2 + log(2*pi)) for each dimension, summed over dimensions.\n",
        "        log_prob_z = -0.5 * torch.sum(z**2 + np.log(2 * np.pi), dim=1)\n",
        "\n",
        "        # Apply the change of variables formula to get log p(x):\n",
        "        # log p(x) = log p(z) + log |det(df/dx)|\n",
        "        return log_prob_z + log_det_jacobian\n",
        "\n",
        "    def sample(self, num_samples):\n",
        "        \"\"\"\n",
        "        Generates new data samples from the trained RealNVP model.\n",
        "\n",
        "        Args:\n",
        "            num_samples (int): The number of samples to generate.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Generated data samples.\n",
        "        \"\"\"\n",
        "        # Sample from the prior (standard Gaussian) in the latent space\n",
        "        z = torch.randn(num_samples, self.input_dim).to(next(self.parameters()).device) # Get device from model parameters\n",
        "        # Transform these latent samples back to the data space using the inverse flow\n",
        "        x = self.inverse(z)\n",
        "        # Clamp values to [0, 1] as original MNIST pixels are in this range\n",
        "        # (after dequantization and normalization, values might slightly exceed 1)\n",
        "        x = torch.clamp(x, 0, 1)\n",
        "        return x\n",
        "\n",
        "# --- 5. Training Loop ---\n",
        "def train_realnvp_model(model, train_loader, optimizer, epochs, device):\n",
        "    \"\"\"\n",
        "    Trains the RealNVP model using the provided data loader and optimizer.\n",
        "\n",
        "    Args:\n",
        "        model (RealNVP): The RealNVP model instance.\n",
        "        train_loader (DataLoader): DataLoader for the training data.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer for model parameters.\n",
        "        epochs (int): Number of training epochs.\n",
        "        device (torch.device): Device to run the training on (CPU or CUDA).\n",
        "    \"\"\"\n",
        "    model.train() # Set the model to training mode\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch_idx, (data, _) in enumerate(train_loader):\n",
        "            data = data.to(device) # Move data to the specified device\n",
        "\n",
        "            optimizer.zero_grad() # Clear gradients from previous step\n",
        "\n",
        "            # Calculate the log-likelihood of the data under the model\n",
        "            log_likelihood = model.log_prob(data)\n",
        "\n",
        "            # The loss is the negative mean log-likelihood (we want to maximize likelihood)\n",
        "            loss = -torch.mean(log_likelihood)\n",
        "\n",
        "            loss.backward() # Backpropagate to compute gradients\n",
        "            optimizer.step() # Update model parameters\n",
        "\n",
        "            total_loss += loss.item() # Accumulate loss for reporting\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "    print(\"Training finished.\")\n",
        "\n",
        "# --- 6. Generate Samples and Visualize ---\n",
        "def generate_samples(model, num_samples=64, img_size=(28, 28), show=True):\n",
        "    \"\"\"\n",
        "    Generates samples from the trained model and visualizes them.\n",
        "\n",
        "    Args:\n",
        "        model (RealNVP): The trained RealNVP model instance.\n",
        "        num_samples (int): Number of samples to generate.\n",
        "        img_size (tuple): Tuple (height, width) for reshaping samples back to image format.\n",
        "        show (bool): If True, displays the generated samples using matplotlib.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The generated samples.\n",
        "    \"\"\"\n",
        "    model.eval() # Set model to evaluation mode (disables dropout, batchnorm etc. if present)\n",
        "    print(f\"Generating {num_samples} samples...\")\n",
        "    with torch.no_grad(): # Disable gradient calculations during inference/sampling\n",
        "        samples = model.sample(num_samples).cpu() # Get samples and move them to CPU for plotting\n",
        "        # Reshape the flattened vectors back into image format (Batch, Channels, Height, Width)\n",
        "        samples = samples.view(-1, 1, img_size[0], img_size[1])\n",
        "\n",
        "        if show:\n",
        "            fig = plt.figure(figsize=(8, 8)) # Create a figure for plotting\n",
        "            # Determine grid size for subplots (e.g., 8x8 for 64 samples)\n",
        "            grid_size = int(np.sqrt(num_samples))\n",
        "            for i in range(num_samples):\n",
        "                ax = fig.add_subplot(grid_size, grid_size, i + 1)\n",
        "                # imshow expects (H, W) for grayscale, so squeeze the channel dimension\n",
        "                ax.imshow(samples[i].squeeze().numpy(), cmap='gray_r') # 'gray_r' for white background\n",
        "                ax.axis('off') # Turn off axes for cleaner image display\n",
        "            plt.suptitle('Generated MNIST Digits (RealNVP Model)') # Set overall title\n",
        "            plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap\n",
        "            plt.show() # Display the plot\n",
        "        return samples\n",
        "\n",
        "# --- Main execution block ---\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Hyperparameters ---\n",
        "    INPUT_DIM = 28 * 28  # Dimension of flattened MNIST images (784 pixels)\n",
        "    HIDDEN_DIM = 1000   # Size of hidden layers within the ScaleAndTranslateNet (can be tuned)\n",
        "    NUM_COUPLING_LAYERS = 4 # Number of affine coupling layers in the flow (can be tuned)\n",
        "    BATCH_SIZE = 128    # Number of samples per training batch\n",
        "    EPOCHS = 20         # Number of training iterations over the entire dataset (can be increased)\n",
        "    # LEARNING_RATE = 1e-3 # Learning rate for the Adam optimizer\n",
        "    LEARNING_RATE = 1e-5 # Learning rate for the Adam optimizer\n",
        "\n",
        "    # --- Device Configuration ---\n",
        "    # Check if CUDA (GPU) is available, otherwise use CPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # --- Load Data ---\n",
        "    # Get training and testing data loaders\n",
        "    train_loader, _ = load_mnist_data(BATCH_SIZE)\n",
        "\n",
        "    # --- Initialize Model and Optimizer ---\n",
        "    # Create an instance of the RealNVP model and move it to the selected device\n",
        "    model = RealNVP(INPUT_DIM, NUM_COUPLING_LAYERS, HIDDEN_DIM).to(device)\n",
        "    # Use Adam optimizer for training the model parameters\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # --- Train the Model ---\n",
        "    train_realnvp_model(model, train_loader, optimizer, EPOCHS, device)\n",
        "\n",
        "    # --- Generate and Visualize Samples ---\n",
        "    # Generate 64 samples and display them\n",
        "    generate_samples(model, num_samples=64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HdKyTGWA66AN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMTBftDJJxwFcQz1dOmLSiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}