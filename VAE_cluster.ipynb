{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM12EA6fc0/463/TwIEg1rA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Papa-Panda/Paper_reading/blob/main/VAE_cluster.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eb_pM6JBMZQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5X9AoQ0JJbL",
        "outputId": "5ae5bc64-568f-4a0b-d74f-b79fb88648d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Starting training...\n",
            "Epoch 1/50, Loss: 56.5785\n",
            "Epoch 2/50, Loss: 44.9978\n",
            "Epoch 3/50, Loss: 43.8118\n",
            "Epoch 4/50, Loss: 43.1163\n",
            "Epoch 5/50, Loss: 42.6250\n",
            "Epoch 6/50, Loss: 42.3200\n",
            "Epoch 7/50, Loss: 42.0678\n",
            "Epoch 8/50, Loss: 41.7940\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "BATCH_SIZE = 100\n",
        "LATENT_DIM = 20\n",
        "EPOCHS = 50\n",
        "NUM_CLASSES = 10\n",
        "IMG_DIM = 28\n",
        "FILTERS = 16\n",
        "INTERMEDIATE_DIM = 256\n",
        "LAMBDA = 2.5 # Weight for reconstruction loss\n",
        "\n",
        "# --- 1. Data Loading and Preprocessing ---\n",
        "def load_mnist_data(batch_size=100):\n",
        "    \"\"\"\n",
        "    Loads and preprocesses the MNIST dataset using PyTorch's DataLoader.\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(), # Converts to tensor and scales to [0, 1]\n",
        "    ])\n",
        "\n",
        "    # Check if data directory exists, create if not\n",
        "    data_dir = './data'\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.makedirs(data_dir)\n",
        "\n",
        "    train_dataset = datasets.MNIST(data_dir, train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.MNIST(data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# --- 2. VAE Model Components ---\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The Encoder network, which maps an input image to the latent space\n",
        "    by outputting a mean (z_mean) and log-variance (z_log_var) vector.\n",
        "    \"\"\"\n",
        "    def __init__(self, latent_dim=20):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # The final feature map dimensions after the conv layers are 7x7\n",
        "        # and the number of channels is FILTERS*4 (16*4=64).\n",
        "        self.h_shape = (FILTERS * 4, 7, 7)\n",
        "        self.h_prod = np.prod(self.h_shape)\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            # Block 1: Input (1, 28, 28) -> Output (32, 14, 14)\n",
        "            nn.Conv2d(1, FILTERS*2, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(FILTERS*2, FILTERS*2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            # Block 2: Input (32, 14, 14) -> Output (64, 7, 7)\n",
        "            nn.Conv2d(FILTERS*2, FILTERS*4, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(FILTERS*4, FILTERS*4, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.fc_mean = nn.Linear(self.h_prod, self.latent_dim)\n",
        "        self.fc_log_var = nn.Linear(self.h_prod, self.latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.conv_layers(x)\n",
        "        h = h.view(h.size(0), -1) # Flatten\n",
        "        z_mean = self.fc_mean(h)\n",
        "        z_log_var = self.fc_log_var(h)\n",
        "        return z_mean, z_log_var\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The Decoder network, which reconstructs an image from a latent vector z.\n",
        "    \"\"\"\n",
        "    def __init__(self, latent_dim=20):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        # The starting feature map shape for the decoder is the final shape of the encoder.\n",
        "        self.h_shape = (FILTERS * 4, 7, 7) # Should be (64, 7, 7)\n",
        "        self.h_prod = np.prod(self.h_shape)\n",
        "\n",
        "        self.dense = nn.Linear(self.latent_dim, self.h_prod)\n",
        "\n",
        "        self.deconv_layers = nn.Sequential(\n",
        "            # Block 1: Input (64, 7, 7) -> Output (32, 14, 14)\n",
        "            nn.ConvTranspose2d(FILTERS*4, FILTERS*4, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.ConvTranspose2d(FILTERS*4, FILTERS*2, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            # Block 2: Input (32, 14, 14) -> Output (16, 28, 28)\n",
        "            nn.ConvTranspose2d(FILTERS*2, FILTERS*2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.ConvTranspose2d(FILTERS*2, FILTERS, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            # Final layer for reconstruction: Input (16, 28, 28) -> Output (1, 28, 28)\n",
        "            nn.ConvTranspose2d(FILTERS, 1, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Sigmoid(), # Output activation for pixel values in [0, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = self.dense(z)\n",
        "        h = h.view(h.size(0), *self.h_shape) # Reshape\n",
        "        x_recon = self.deconv_layers(h)\n",
        "        return x_recon\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple classifier that predicts the digit class from the latent vector z.\n",
        "    \"\"\"\n",
        "    def __init__(self, latent_dim=20, num_classes=10):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(latent_dim, INTERMEDIATE_DIM),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(INTERMEDIATE_DIM, num_classes),\n",
        "            nn.Softmax(dim=1) # Softmax activation for class probabilities\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.net(z)\n",
        "\n",
        "class GaussianPrior(nn.Module):\n",
        "    \"\"\"\n",
        "    A custom layer to represent the means of the conditional Gaussian prior p(z|y).\n",
        "    This layer holds a learnable mean vector for each class.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10, latent_dim=20):\n",
        "        super(GaussianPrior, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.latent_dim = latent_dim\n",
        "        # `mean` is a learnable parameter of shape (num_classes, latent_dim)\n",
        "        self.mean = nn.Parameter(torch.zeros(num_classes, latent_dim))\n",
        "\n",
        "    def forward(self, z, y_pred):\n",
        "        # z: (batch_size, latent_dim)\n",
        "        # y_pred: (batch_size, num_classes)\n",
        "        # Use y_pred to get a weighted sum of prior means for each sample\n",
        "        z_prior_mean = torch.matmul(y_pred.unsqueeze(1), self.mean.unsqueeze(0))\n",
        "        z_prior_mean = z_prior_mean.squeeze(1) # Squeeze to shape (batch_size, latent_dim)\n",
        "        return z_prior_mean\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    \"\"\"\n",
        "    The main VAE model, combining the Encoder, Decoder, Classifier,\n",
        "    and a Gaussian Prior layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, latent_dim=20, num_classes=10):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = Encoder(latent_dim)\n",
        "        self.decoder = Decoder(latent_dim)\n",
        "        self.classifier = Classifier(latent_dim, num_classes)\n",
        "        self.gaussian_prior = GaussianPrior(num_classes, latent_dim)\n",
        "\n",
        "    def reparameterize(self, z_mean, z_log_var):\n",
        "        \"\"\"Reparameterization trick to sample z from the latent distribution.\"\"\"\n",
        "        std = torch.exp(0.5 * z_log_var)\n",
        "        epsilon = torch.randn_like(std)\n",
        "        return z_mean + std * epsilon\n",
        "\n",
        "    def forward(self, x):\n",
        "        z_mean, z_log_var = self.encoder(x)\n",
        "        z = self.reparameterize(z_mean, z_log_var)\n",
        "        x_recon = self.decoder(z)\n",
        "        y = self.classifier(z)\n",
        "        z_prior_mean = self.gaussian_prior(z, y)\n",
        "\n",
        "        return x_recon, z_mean, z_log_var, z_prior_mean, y, z\n",
        "\n",
        "# --- 3. Custom Loss Function ---\n",
        "def vae_loss_function(x, x_recon, z_mean, z_log_var, z_prior_mean, y):\n",
        "    \"\"\"\n",
        "    Custom VAE loss function as described in the Keras code.\n",
        "    It combines reconstruction loss, KL divergence, and a categorical loss term.\n",
        "    \"\"\"\n",
        "    # Reconstruction Loss (Mean Squared Error)\n",
        "    xent_loss = 0.5 * F.mse_loss(x, x_recon, reduction='none').sum(dim=[1, 2, 3])\n",
        "\n",
        "    # KL Divergence Loss\n",
        "    # KL(q(z|x) || p(z|y)) = 0.5 * sum(var + (mean - prior_mean)^2 - log(var) - 1)\n",
        "    kl_loss = -0.5 * torch.sum(z_log_var - torch.square(z_mean - z_prior_mean) - torch.exp(z_log_var), dim=1)\n",
        "\n",
        "    # Categorical Loss (Negative Entropy)\n",
        "    # The Keras code uses K.mean(y * K.log(y + K.epsilon()), 0), which is negative entropy.\n",
        "    # This term encourages the classifier output to be 'flat' (high entropy),\n",
        "    # which is a common technique in unsupervised clustering with VAEs.\n",
        "    cat_loss = -torch.sum(y * torch.log(y + 1e-8), dim=1)\n",
        "\n",
        "    # Total VAE loss\n",
        "    total_loss = (LAMBDA * xent_loss + kl_loss + cat_loss).mean()\n",
        "    return total_loss\n",
        "\n",
        "# --- 4. Training and Evaluation ---\n",
        "def train(model, train_loader, optimizer, device, epochs):\n",
        "    \"\"\"\n",
        "    Training loop for the VAE model.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for data, _ in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x_recon, z_mean, z_log_var, z_prior_mean, y, _ = model(data)\n",
        "            loss = vae_loss_function(data, x_recon, z_mean, z_log_var, z_prior_mean, y)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}')\n",
        "    print(\"Training finished.\")\n",
        "\n",
        "def generate_samples(model, means, std=1.0, device='cpu', num_samples_per_class=8, img_dim=28):\n",
        "    \"\"\"\n",
        "    Generates samples conditioned on the learned class means.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_images = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(NUM_CLASSES):\n",
        "            # Sample from the Gaussian prior for the current class\n",
        "            noise = torch.randn(num_samples_per_class, LATENT_DIM).to(device) * std\n",
        "            z_sample = noise + means[i]\n",
        "\n",
        "            # Decode the latent vector to an image\n",
        "            x_recon = model.decoder(z_sample).cpu()\n",
        "            all_images.append(x_recon)\n",
        "\n",
        "    all_images = torch.cat(all_images, dim=0)\n",
        "\n",
        "    # Visualize the generated images\n",
        "    fig = plt.figure(figsize=(num_samples_per_class, NUM_CLASSES))\n",
        "    grid_size_h = num_samples_per_class\n",
        "    grid_size_w = NUM_CLASSES\n",
        "\n",
        "    for i in range(NUM_CLASSES * num_samples_per_class):\n",
        "        ax = fig.add_subplot(grid_size_w, grid_size_h, i + 1)\n",
        "        ax.imshow(all_images[i].squeeze().numpy(), cmap='gray_r')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.suptitle('Generated Samples per Class')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --- Main execution block ---\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    train_loader, test_loader = load_mnist_data(BATCH_SIZE)\n",
        "\n",
        "    model = VAE(LATENT_DIM, NUM_CLASSES).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    train(model, train_loader, optimizer, device, EPOCHS)\n",
        "\n",
        "    # After training, get the learned means from the Gaussian Prior layer\n",
        "    learned_means = model.gaussian_prior.mean.detach().cpu()\n",
        "\n",
        "    # Generate and visualize samples for each class\n",
        "    generate_samples(model, learned_means, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FP37qFX9JKZB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}