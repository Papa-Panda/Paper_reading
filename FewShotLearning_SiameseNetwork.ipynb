{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeytDYZRgqEn7fijb7ziHX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Papa-Panda/Paper_reading/blob/main/FewShotLearning_SiameseNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YoOgiWVdGBpn"
      },
      "outputs": [],
      "source": [
        "#【Few-Shot Learning (1/3): 基本概念】 https://www.bilibili.com/video/BV1V44y1r7cx/?share_source=copy_web&vd_source=cdc9fab15e0ce1d464719ce689a12b14"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "import random\n"
      ],
      "metadata": {
        "id": "kHcLJfs_GI22"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseDataset(Dataset):\n",
        "# class SiameseMNISTDataset(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset  # MNIST dataset\n",
        "        self.transform = transform\n",
        "\n",
        "        # Create a dictionary to quickly access all samples by class\n",
        "        self.class_to_indices = self._group_by_class()\n",
        "\n",
        "    def _group_by_class(self):\n",
        "        class_dict = {}\n",
        "        for idx, (_, label) in enumerate(self.dataset):\n",
        "            if label not in class_dict:\n",
        "                class_dict[label] = []\n",
        "            class_dict[label].append(idx)\n",
        "        return class_dict\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img1, label1 = self.dataset[idx]\n",
        "\n",
        "        # Decide if the pair should be positive (same class) or negative (different class)\n",
        "        is_same = random.randint(0, 1)\n",
        "\n",
        "        if is_same:\n",
        "            # Positive pair: Select another image from the same class\n",
        "            img2_idx = random.choice(self.class_to_indices[label1])\n",
        "            label = 1.0\n",
        "        else:\n",
        "            # Negative pair: Select a random image from a different class\n",
        "            other_label = random.choice([x for x in range(10) if x != label1])\n",
        "            img2_idx = random.choice(self.class_to_indices[other_label])\n",
        "            label = 0.0\n",
        "\n",
        "        img2, _ = self.dataset[img2_idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "\n",
        "        return (img1, img2), torch.tensor(label, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "EH_BMCxAGR-8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def siamese_network(input_shape):\n",
        "    shared_network = create_shared_network(input_shape)\n",
        "\n",
        "    # Define the two inputs\n",
        "    input_a = Input(shape=input_shape)\n",
        "    input_b = Input(shape=input_shape)\n",
        "\n",
        "    # Get feature vectors from the shared network\n",
        "    encoded_a = shared_network(input_a)\n",
        "    encoded_b = shared_network(input_b)\n",
        "\n",
        "    # Compute the L1 distance between the two feature vectors\n",
        "    l1_distance = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))([encoded_a, encoded_b])\n",
        "\n",
        "    # Add a dense layer with sigmoid activation to get the similarity score\n",
        "    outputs = Dense(1, activation='sigmoid')(l1_distance)\n",
        "\n",
        "    return Model(inputs=[input_a, input_b], outputs=outputs)\n"
      ],
      "metadata": {
        "id": "4vRwzPMiGX4a"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\n",
        "class SiameseDataset(Dataset):\n",
        "    def __init__(self, size=1000, transform=None):\n",
        "        self.size = size  # Total number of pairs\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Randomly generate two 1D \"images\" (vector) of size 10\n",
        "        image1 = torch.randn(10)\n",
        "        label = random.randint(0, 1)  # 1 for \"same\", 0 for \"different\"\n",
        "\n",
        "        if label == 1:\n",
        "            # Positive pair: Same class (for simplicity, similar vector)\n",
        "            image2 = image1 + torch.randn(10) * 0.1\n",
        "        else:\n",
        "            # Negative pair: Different classes (random vector)\n",
        "            image2 = torch.randn(10)\n",
        "\n",
        "        if self.transform:\n",
        "            image1 = self.transform(image1)\n",
        "            image2 = self.transform(image2)\n",
        "\n",
        "        return (image1, image2), torch.tensor(label, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "a11bIKAzGaZs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_pairs(data, labels, num_classes):\n",
        "    pairs = []\n",
        "    labels_pair = []\n",
        "\n",
        "    # Create positive and negative pairs\n",
        "    for class_idx in range(num_classes):\n",
        "        class_indices = np.where(labels == class_idx)[0]\n",
        "        np.random.shuffle(class_indices)\n",
        "\n",
        "        # Generate positive pairs\n",
        "        for i in range(len(class_indices) - 1):\n",
        "            pairs += [[data[class_indices[i]], data[class_indices[i + 1]]]]\n",
        "            labels_pair += [1]\n",
        "\n",
        "        # Generate negative pairs\n",
        "        other_class = (class_idx + 1) % num_classes\n",
        "        other_class_indices = np.where(labels == other_class)[0]\n",
        "        pairs += [[data[class_indices[0]], data[other_class_indices[0]]]]\n",
        "        labels_pair += [0]\n",
        "\n",
        "    return np.array(pairs), np.array(labels_pair)\n"
      ],
      "metadata": {
        "id": "xt-rdpfgGdVT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),  # Input: (B, 1, 28, 28)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # Output: (B, 32, 14, 14)\n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),  # Output: (B, 64, 14, 14)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)  # Output: (B, 64, 7, 7)\n",
        "        )\n",
        "\n",
        "        # Calculate the flattened size of the output: 64 * 7 * 7 = 3136\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # Pass both images through the same convolutional layers\n",
        "        out1 = self.conv(x1)  # Shape: (B, 64, 7, 7)\n",
        "        out2 = self.conv(x2)  # Shape: (B, 64, 7, 7)\n",
        "\n",
        "        # Flatten the outputs to (B, 3136)\n",
        "        out1 = out1.view(out1.size(0), -1)\n",
        "        out2 = out2.view(out2.size(0), -1)\n",
        "\n",
        "        # Encode both images using the fully connected layers\n",
        "        out1 = self.fc(out1)\n",
        "        out2 = self.fc(out2)\n",
        "\n",
        "        # Return the L1 distance between the two encodings\n",
        "        return torch.abs(out1 - out2)\n"
      ],
      "metadata": {
        "id": "Y8JoNx3cGiLD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, distance, label):\n",
        "        pos_loss = label * torch.pow(distance, 2)\n",
        "        neg_loss = (1 - label) * torch.pow(torch.clamp(self.margin - distance, min=0), 2)\n",
        "        loss = 0.5 * torch.mean(pos_loss + neg_loss)\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "P5fKzexmGmSr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Load the train and test datasets\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create the Siamese Datasets\n",
        "train_loader = DataLoader(SiameseMNISTDataset(train_dataset), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(SiameseMNISTDataset(test_dataset), batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij3FkL8AmK3I",
        "outputId": "814bc593-8673-4afb-9929-8c785758d552"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.68MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.19MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 5.57MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.54MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6\n",
        "model = SiameseNetwork()\n",
        "criterion = ContrastiveLoss(margin=1.0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for (img1, img2), label in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        distance = model(img1, img2).norm(p=1, dim=1)\n",
        "        # Compute loss\n",
        "        loss = criterion(distance, label)\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/10], Loss: {total_loss / len(train_loader):.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dADOC1BDm6Zx",
        "outputId": "3e319bde-8940-495a-a107-e5e44c503106"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.0216\n",
            "Epoch [2/10], Loss: 0.0078\n",
            "Epoch [3/10], Loss: 0.0060\n",
            "Epoch [4/10], Loss: 0.0047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (img1, img2), label in data_loader:\n",
        "            distance = model(img1, img2).norm(p=1, dim=1)\n",
        "            prediction = (distance < 0.5).float()  # Threshold at 0.5\n",
        "            correct += (prediction == label).sum().item()\n",
        "            total += label.size(0)\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    print(f'Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Evaluate on the test dataset\n",
        "evaluate(model, test_loader)\n"
      ],
      "metadata": {
        "id": "P6yhkoY5m81C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0Nacv-nn_vc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}