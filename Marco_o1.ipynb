{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOlVCeyYPWIBVPjxBCFXtu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Papa-Panda/Paper_reading/blob/main/Marco_o1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/AIDC-AI/Marco-o1\n",
        "# learning how to do MCTS (Monte Carlo Tree Search)"
      ],
      "metadata": {
        "id": "3_agKUr8t0g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-gQOvZytzKC",
        "outputId": "41f4349f-fe32-40f6-8dbe-5e80829a2b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best reasoning trajectory: tensor([-1.3798,  1.3225,  0.6134,  0.0936, -0.7026, -0.9549, -0.4759,  0.3135,\n",
            "         0.4071,  0.4607])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "# Define a mock reward model to score reasoning steps\n",
        "class RewardModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(10, 1)  # Input: Reasoning embeddings, Output: Reward score\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Initialize the reward model\n",
        "reward_model = RewardModel()\n",
        "\n",
        "# Mock function to simulate reasoning step generation\n",
        "def generate_reasoning_step(state):\n",
        "    \"\"\"\n",
        "    Simulates a reasoning step by slightly modifying the current state.\n",
        "    Each step is represented as a tensor embedding.\n",
        "    \"\"\"\n",
        "    return state + torch.randn_like(state) * 0.1\n",
        "\n",
        "# Monte Carlo Tree Node\n",
        "class TreeNode:\n",
        "    def __init__(self, state, parent=None):\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.children = []\n",
        "        self.visits = 0\n",
        "        self.value = 0\n",
        "\n",
        "    def add_child(self, child):\n",
        "        self.children.append(child)\n",
        "\n",
        "# MCTS Algorithm\n",
        "class MCTS:\n",
        "    def __init__(self, reward_model, exploration_weight=1.0):\n",
        "        self.reward_model = reward_model\n",
        "        self.exploration_weight = exploration_weight\n",
        "\n",
        "    def select_node(self, node):\n",
        "        \"\"\"Select the child node with the highest UCB score.\"\"\"\n",
        "        best_score = float('-inf')\n",
        "        best_child = None\n",
        "        for child in node.children:\n",
        "            # Calculate Upper Confidence Bound (UCB)\n",
        "            exploit = child.value / (child.visits + 1e-5)\n",
        "            explore = self.exploration_weight * torch.sqrt(torch.log(torch.tensor(node.visits + 1.0)) / (torch.tensor(child.visits + 1e-5)))\n",
        "            score = exploit + explore\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_child = child\n",
        "        return best_child\n",
        "\n",
        "    def expand_node(self, node):\n",
        "        \"\"\"Expand the current node by generating new reasoning steps.\"\"\"\n",
        "        for _ in range(3):  # Generate 3 possible reasoning steps\n",
        "            new_state = generate_reasoning_step(node.state)\n",
        "            child_node = TreeNode(new_state, parent=node)\n",
        "            node.add_child(child_node)\n",
        "\n",
        "    def simulate(self, node):\n",
        "        \"\"\"Simulate a rollout from the current node.\"\"\"\n",
        "        current_state = node.state.clone()\n",
        "        for _ in range(5):  # Perform 5 random reasoning steps\n",
        "            current_state = generate_reasoning_step(current_state)\n",
        "        # Evaluate the trajectory with the reward model\n",
        "        reward = self.reward_model(current_state).item()\n",
        "        return reward\n",
        "\n",
        "    def backpropagate(self, node, reward):\n",
        "        \"\"\"Backpropagate the reward up the tree.\"\"\"\n",
        "        while node is not None:\n",
        "            node.visits += 1\n",
        "            node.value += reward\n",
        "            node = node.parent\n",
        "\n",
        "    def search(self, root, num_simulations=50):\n",
        "        \"\"\"Perform MCTS starting from the root node.\"\"\"\n",
        "        for _ in range(num_simulations):\n",
        "            node = root\n",
        "            # Selection\n",
        "            while node.children:\n",
        "                node = self.select_node(node)\n",
        "            # Expansion\n",
        "            self.expand_node(node)\n",
        "            # Simulation\n",
        "            reward = self.simulate(node)\n",
        "            # Backpropagation\n",
        "            self.backpropagate(node, reward)\n",
        "        # Return the best child\n",
        "        return max(root.children, key=lambda child: child.visits)\n",
        "\n",
        "# Initial state (randomly initialized embedding)\n",
        "initial_state = torch.randn(10)\n",
        "root_node = TreeNode(initial_state)\n",
        "\n",
        "# Perform MCTS\n",
        "mcts = MCTS(reward_model)\n",
        "best_node = mcts.search(root_node)\n",
        "\n",
        "print(\"Best reasoning trajectory:\", best_node.state)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ysLojCGuAfm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}