{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMll/qDzLSfj85hGlaZKAb4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Papa-Panda/Paper_reading/blob/main/AlphaGo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp7-LIujRhKm",
        "outputId": "2f4ab600-3ddb-4999-a616-532b39c148d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6759\n",
            "Epoch 2, Loss: 0.6712\n",
            "Epoch 3, Loss: 0.6646\n",
            "Epoch 4, Loss: 0.6650\n",
            "Epoch 5, Loss: 0.6649\n",
            "Epoch 6, Loss: 0.6655\n",
            "Epoch 7, Loss: 0.6654\n",
            "Epoch 8, Loss: 0.6649\n",
            "Epoch 9, Loss: 0.6643\n",
            "Epoch 10, Loss: 0.6643\n",
            "Sample Policy Output: [[1.74505869e-04 1.00048957e-04 4.68107779e-03 8.30252189e-03\n",
            "  1.50735184e-04 7.09612359e-05 1.43133942e-02 2.00251307e-04\n",
            "  2.17691253e-04 1.14968456e-02 1.87502810e-04 1.10543406e-04\n",
            "  3.88346525e-04 1.89784609e-04 8.88134455e-05 1.19790726e-04\n",
            "  1.23454526e-03 3.78453959e-04 2.49162840e-04 5.89653244e-03\n",
            "  5.12389094e-03 3.72252194e-04 2.08187499e-04 9.02030058e-03\n",
            "  8.07481993e-05 1.54934329e-04 5.37571823e-03 3.41055333e-04\n",
            "  9.17945465e-04 4.64270590e-03 1.87805170e-04 1.14766613e-03\n",
            "  1.68724859e-04 2.34748982e-03 1.08893623e-03 1.42826354e-02\n",
            "  1.68903556e-04 2.53110949e-04 5.10392291e-03 1.09903878e-04\n",
            "  1.98277342e-03 4.61724633e-03 6.34160533e-04 1.97918643e-03\n",
            "  2.23617084e-04 4.49238578e-05 6.36371376e-04 1.60747059e-02\n",
            "  8.58140629e-05 1.23300255e-04 1.55682530e-04 6.65226034e-05\n",
            "  6.22216752e-03 8.66594259e-03 1.25685276e-03 5.82716009e-03\n",
            "  7.27828126e-03 9.71609633e-03 1.42765814e-04 1.27155348e-04\n",
            "  2.71967752e-03 9.25237182e-05 1.34713587e-03 4.52282344e-04\n",
            "  2.17420806e-04 6.78540237e-05 9.29713715e-04 1.41648389e-02\n",
            "  9.24150553e-03 3.45275417e-04 2.93610763e-04 4.10951499e-04\n",
            "  3.16688255e-03 1.38021521e-02 9.33351621e-05 3.12029570e-03\n",
            "  5.93268720e-04 4.57900926e-04 9.61712867e-05 6.03270158e-03\n",
            "  2.38108172e-04 1.06676809e-04 4.64076846e-04 9.66737280e-04\n",
            "  4.38161101e-03 6.61786107e-05 2.38481490e-03 2.80860369e-03\n",
            "  1.74846282e-04 7.48764869e-05 1.03169834e-04 1.06735017e-04\n",
            "  6.47634370e-05 3.35538504e-03 1.50357168e-02 5.67847965e-05\n",
            "  4.72557917e-03 5.73950965e-05 6.86941421e-05 3.73806251e-04\n",
            "  7.53062544e-04 7.74990476e-05 5.78779473e-05 7.39382813e-04\n",
            "  1.98089820e-03 9.89239104e-03 6.67656495e-05 2.85501895e-03\n",
            "  1.04173152e-04 1.19255588e-03 1.52161997e-02 6.23647720e-05\n",
            "  6.69181487e-03 2.54552840e-04 7.14737835e-05 5.95996855e-04\n",
            "  6.79871254e-03 7.21875767e-05 5.22343653e-05 1.89227168e-04\n",
            "  1.08110340e-04 7.67087389e-04 1.40081262e-04 1.05027249e-02\n",
            "  1.41763128e-02 3.36050638e-03 1.42667964e-02 7.97389727e-03\n",
            "  1.20484235e-03 1.40498567e-04 1.14583148e-04 2.63686432e-03\n",
            "  4.67364371e-05 7.57039306e-05 1.62130110e-02 1.03789782e-04\n",
            "  6.80388985e-05 1.75048748e-03 4.76785295e-04 1.01774640e-04\n",
            "  1.57933903e-03 1.37825310e-02 2.01785425e-03 4.07972839e-03\n",
            "  6.69421643e-05 5.24232048e-04 1.79272974e-04 9.57434240e-04\n",
            "  7.99543282e-04 1.30627901e-04 2.93735764e-03 9.37614765e-04\n",
            "  8.86508729e-03 6.12947252e-03 1.61400028e-02 1.14305904e-02\n",
            "  6.27253298e-03 5.41447662e-03 5.15940701e-05 6.67075728e-05\n",
            "  1.30235945e-04 8.15371895e-05 1.51093904e-04 1.06830841e-04\n",
            "  3.75797739e-04 7.74177082e-04 1.13151222e-03 1.25593971e-04\n",
            "  9.58740804e-03 1.47112841e-02 7.45107754e-05 4.83539945e-04\n",
            "  2.45075556e-04 3.49637214e-03 3.42812832e-03 9.98807445e-05\n",
            "  8.14757077e-04 6.02094879e-05 1.04656050e-04 4.47101120e-05\n",
            "  2.93891062e-04 7.65098303e-05 2.70124222e-03 4.96648026e-05\n",
            "  3.19109735e-04 7.53603308e-05 5.98710403e-03 1.26121826e-02\n",
            "  3.02262750e-04 6.76296791e-03 6.21002400e-03 6.51486276e-04\n",
            "  5.20561961e-03 8.29652126e-05 7.09526430e-05 1.21833618e-04\n",
            "  4.03874274e-03 1.60547160e-03 7.77348829e-03 7.18533920e-05\n",
            "  1.05319421e-04 3.99538229e-04 1.98156899e-03 1.23739883e-04\n",
            "  4.23922110e-03 1.36923855e-02 7.55275134e-03 9.57054872e-05\n",
            "  1.49272690e-02 2.68823322e-04 1.22676691e-04 6.58869452e-04\n",
            "  9.00138839e-05 7.32258835e-04 2.67938536e-04 1.60443108e-03\n",
            "  9.08526033e-03 6.31066214e-04 1.86047750e-04 8.97628852e-05\n",
            "  2.76734470e-04 3.23409848e-02 1.41289290e-02 1.22839736e-03\n",
            "  4.83378790e-05 2.24194053e-04 6.57365192e-03 2.05303007e-03\n",
            "  6.30766226e-05 1.98560432e-04 2.73919723e-04 8.06607641e-05\n",
            "  2.97188635e-05 2.56539788e-04 5.14677449e-05 5.94698638e-03\n",
            "  4.11175337e-04 2.77521415e-03 2.74811732e-03 1.64588753e-04\n",
            "  1.92660256e-04 4.10434477e-05 1.55411573e-04 1.06457341e-02\n",
            "  4.22997307e-03 3.12595163e-04 8.92111057e-05 5.47310337e-03\n",
            "  1.69256047e-04 1.21417479e-03 3.00743413e-04 3.70026962e-03\n",
            "  4.57896199e-03 1.17658060e-02 1.11889420e-03 4.63167526e-05\n",
            "  5.40751126e-03 7.41410942e-04 1.04943247e-04 3.03916982e-04\n",
            "  1.31799970e-04 1.16185902e-03 1.60970842e-04 2.02672742e-03\n",
            "  1.03898568e-03 1.39012067e-02 2.81122699e-03 6.44916654e-05\n",
            "  6.70118825e-05 1.48928922e-03 4.87316342e-04 4.15147624e-05\n",
            "  3.61684739e-04 7.22940918e-03 4.62498865e-04 1.65362202e-04\n",
            "  5.43614988e-05 1.37386043e-02 5.11143077e-03 6.40832586e-04\n",
            "  4.23191814e-03 6.88481377e-05 8.93410202e-03 4.84977354e-04\n",
            "  7.65332879e-05 8.11372139e-03 3.79997632e-03 5.97723667e-03\n",
            "  5.18305169e-05 1.64253707e-03 1.39053003e-03 1.91945757e-04\n",
            "  1.92251336e-03 3.50578281e-04 6.37179706e-04 1.26139661e-02\n",
            "  2.61725439e-03 3.67015746e-05 1.20196380e-02 1.23509788e-03\n",
            "  7.41791737e-05 4.90184502e-05 3.09650647e-03 1.50963210e-03\n",
            "  8.01871624e-03 1.06502783e-04 7.38954637e-04 1.60706782e-04\n",
            "  1.06615284e-02 1.10458677e-04 3.62238893e-03 1.78629838e-04\n",
            "  3.32886772e-03 2.17714738e-02 1.90494902e-04 4.83789918e-05\n",
            "  3.48374102e-04 2.86867935e-03 3.81433674e-05 3.68640060e-04\n",
            "  1.39660726e-03 3.74893716e-04 5.13603911e-04 5.39380405e-03\n",
            "  9.49102687e-05 1.92701519e-02 1.37796000e-04 1.08900275e-02\n",
            "  1.13607457e-04 9.25756176e-05 1.68415238e-04 1.40777280e-04\n",
            "  2.47717922e-04 4.00540011e-05 2.70806049e-04 1.30274071e-04\n",
            "  1.13662181e-03 1.07797103e-04 7.31466711e-03 1.62143784e-04\n",
            "  7.70365077e-05 8.11971986e-05 2.22358154e-04 8.38548876e-05\n",
            "  6.25288486e-03 5.88465482e-03 7.51759580e-05 1.27713487e-04\n",
            "  1.45524340e-02 4.06979723e-03 1.80275252e-04 1.15781229e-04\n",
            "  6.85468432e-04 3.01755412e-04 4.39338037e-04 3.35927070e-05\n",
            "  6.16611773e-03 1.27589679e-04 2.51685618e-04 5.87896071e-03\n",
            "  1.15110241e-04]]\n",
            "Sample Value Output: [[-0.01871404]]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "def create_random_go_data(num_samples=1000, board_size=19):\n",
        "    \"\"\"Generate pseudo-training data with random board states and move probabilities.\"\"\"\n",
        "    X = np.random.randint(0, 3, (num_samples, 1, board_size, board_size)).astype(np.float32)  # Board state (1 channel)\n",
        "    y_policy = np.random.rand(num_samples, board_size * board_size).astype(np.float32)  # Move probabilities\n",
        "    y_value = np.random.uniform(-1, 1, (num_samples, 1)).astype(np.float32)  # Game outcome (-1 to 1)\n",
        "    return torch.tensor(X), torch.tensor(y_policy), torch.tensor(y_value)\n",
        "\n",
        "class AlphaGoNet(nn.Module):\n",
        "    def __init__(self, board_size=19):\n",
        "        super(AlphaGoNet, self).__init__()\n",
        "        self.board_size = board_size\n",
        "\n",
        "        # Common Feature Extraction\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Policy Head\n",
        "        self.policy_head = nn.Sequential(\n",
        "            nn.Conv2d(256, 2, kernel_size=1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2 * board_size * board_size, board_size * board_size),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "        # Value Head\n",
        "        self.value_head = nn.Sequential(\n",
        "            nn.Conv2d(256, 1, kernel_size=1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(board_size * board_size, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 1), nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.conv_layers(x)\n",
        "        policy = self.policy_head(features)\n",
        "        value = self.value_head(features)\n",
        "        return policy, value\n",
        "\n",
        "# Training Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AlphaGoNet().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion_policy = nn.MSELoss()\n",
        "criterion_value = nn.MSELoss()\n",
        "\n",
        "# Generate Random Data\n",
        "X_train, y_policy_train, y_value_train = create_random_go_data()\n",
        "X_train, y_policy_train, y_value_train = X_train.to(device), y_policy_train.to(device), y_value_train.to(device)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(10):  # Small training loop\n",
        "    optimizer.zero_grad()\n",
        "    policy_pred, value_pred = model(X_train)\n",
        "    loss_policy = criterion_policy(policy_pred, y_policy_train)\n",
        "    loss_value = criterion_value(value_pred, y_value_train)\n",
        "    loss = loss_policy + loss_value\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Testing Inference\n",
        "test_board = torch.randint(0, 3, (1, 1, 19, 19), dtype=torch.float32).to(device)\n",
        "policy_out, value_out = model(test_board)\n",
        "print(\"Sample Policy Output:\", policy_out.detach().cpu().numpy())\n",
        "print(\"Sample Value Output:\", value_out.detach().cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGDkaYSNR56D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}